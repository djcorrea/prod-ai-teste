// ğŸµ AUDIO ANALYZER - Sistema de AnÃ¡lise de Ãudio Gratuito
// ImplementaÃ§Ã£o usando Web Audio API (100% gratuito)

class AudioAnalyzer {
  constructor() {
    this.audioContext = null;
    this.analyzer = null;
    this.dataArray = null;
    this.isAnalyzing = false;
  this._v2Loaded = false;
  this._v2LoadingPromise = null;
  }

  // ğŸ¤ Inicializar anÃ¡lise de Ã¡udio
  async initializeAnalyzer() {
    try {
      // Criar contexto de Ã¡udio
      this.audioContext = new (window.AudioContext || window.webkitAudioContext)();
      this.analyzer = this.audioContext.createAnalyser();
      
      // ConfiguraÃ§Ãµes de anÃ¡lise
      this.analyzer.fftSize = 2048;
      this.analyzer.smoothingTimeConstant = 0.8;
      
      const bufferLength = this.analyzer.frequencyBinCount;
      this.dataArray = new Uint8Array(bufferLength);
      
      console.log('ğŸµ Analisador de Ã¡udio inicializado com sucesso');
      return true;
    } catch (error) {
      console.error('âŒ Erro ao inicializar analisador:', error);
      return false;
    }
  }

  // ğŸ“ Analisar arquivo de Ã¡udio
  async analyzeAudioFile(file) {
    const tsStart = new Date().toISOString();
    console.log('ğŸ›°ï¸ [Telemetry] Front antes do fetch (modo local, sem fetch):', {
      route: '(client-only) audio-analyzer.js',
      method: 'N/A',
      file: file?.name,
      sizeBytes: file?.size,
      startedAt: tsStart
    });
    console.log(`ğŸµ Iniciando anÃ¡lise de: ${file.name}`);
    
    if (!this.audioContext) {
      await this.initializeAnalyzer();
    }

    return new Promise((resolve, reject) => {
      // Timeout de 30 segundos
      const timeout = setTimeout(() => {
        reject(new Error('Timeout na anÃ¡lise do Ã¡udio (30s)'));
      }, 30000);

      const reader = new FileReader();
      
      reader.onload = async (e) => {
        try {
          console.log('ğŸ“Š Decodificando Ã¡udio...');
          const audioData = e.target.result;
          const audioBuffer = await this.audioContext.decodeAudioData(audioData);
          
          console.log('ğŸ”¬ Realizando anÃ¡lise completa...');
          // AnÃ¡lise completa do Ã¡udio (V1)
          let analysis = this.performFullAnalysis(audioBuffer);

          // Enriquecimento Fase 2 (sem alterar UI): tenta carregar V2 e mapear novas mÃ©tricas
          try {
            analysis = await this._enrichWithPhase2Metrics(audioBuffer, analysis, file);
          } catch (enrichErr) {
            console.warn('âš ï¸ Falha ao enriquecer com mÃ©tricas Fase 2:', enrichErr?.message || enrichErr);
          }
          
          clearTimeout(timeout);
          console.log('âœ… AnÃ¡lise concluÃ­da com sucesso!');
          // Telemetria pÃ³s-json: chaves de 1Âº nÃ­vel
          try {
            const topKeys = analysis ? Object.keys(analysis) : [];
            const techKeys = analysis?.technicalData ? Object.keys(analysis.technicalData) : [];
            console.log('ğŸ›°ï¸ [Telemetry] Front apÃ³s "json" (obj pronto):', { topLevelKeys: topKeys, technicalKeys: techKeys });
          } catch {}
          resolve(analysis);
        } catch (error) {
          clearTimeout(timeout);
          console.error('âŒ Erro na decodificaÃ§Ã£o:', error);
          reject(new Error(`Erro ao decodificar Ã¡udio: ${error.message}`));
        }
      };
      
      reader.onerror = (error) => {
        clearTimeout(timeout);
        console.error('âŒ Erro ao ler arquivo:', error);
        reject(new Error('Erro ao ler arquivo de Ã¡udio'));
      };
      
      reader.readAsArrayBuffer(file);
    });
  }

  // ğŸ”Œ Enriquecer com mÃ©tricas da Fase 2 usando motor V2 (carregado dinamicamente)
  async _enrichWithPhase2Metrics(audioBuffer, baseAnalysis, fileRef) {
    // Carregar V2 dinamicamente se disponÃ­vel no projeto (sem alterar HTML)
    if (!this._v2Loaded && typeof window.AudioAnalyzerV2 === 'undefined') {
      if (!this._v2LoadingPromise) {
        this._v2LoadingPromise = new Promise((resolve, reject) => {
          const pagePath = (typeof location !== 'undefined') ? location.pathname : '/';
          // Candidatos robustos, mantendo paths relativos ao index atual
          const candidates = [];
          // 1) relativo ao documento atual
          candidates.push('audio-analyzer-v2.js');
          candidates.push('./audio-analyzer-v2.js');
          // 2) se a pÃ¡gina estiver em /public/, tente raiz e /public/
          if (pagePath.includes('/public/')) {
            candidates.push('/public/audio-analyzer-v2.js');
          } else {
            candidates.push('public/audio-analyzer-v2.js');
            candidates.push('/public/audio-analyzer-v2.js');
          }

          console.log('ğŸ›°ï¸ [Telemetry] Tentando carregar V2 a partir de:', candidates);

          let idx = 0;
          const tryNext = () => {
            if (idx >= candidates.length) {
              reject(new Error('Falha ao carregar audio-analyzer-v2.js de todos os caminhos candidatos'));
              return;
            }
            const url = candidates[idx++];
            const s = document.createElement('script');
            s.src = url;
            s.async = true;
            s.onload = () => { this._v2Loaded = true; console.log('âœ… V2 carregado de', url); resolve(); };
            s.onerror = () => { console.warn('âš ï¸ Falha ao carregar V2 em', url); tryNext(); };
            document.head.appendChild(s);
          };
          tryNext();
        });
      }
      try { await this._v2LoadingPromise; } catch (e) { console.warn('âš ï¸ V2 indisponÃ­vel:', e.message); }
    }

    if (typeof window.AudioAnalyzerV2 !== 'function') {
      console.log('â„¹ï¸ Motor V2 nÃ£o disponÃ­vel. Mantendo apenas mÃ©tricas bÃ¡sicas.');
      return baseAnalysis;
    }

  // Executar anÃ¡lise V2 de forma leve usando diretamente o AudioBuffer (evita re-decodificaÃ§Ã£o)
  const v2 = new window.AudioAnalyzerV2();
  await v2.initialize?.();
  console.log('ğŸ›°ï¸ [Telemetry] V2: performFullAnalysis com audioBuffer.');
  const v2res = await v2.performFullAnalysis(audioBuffer, { quality: 'fast', features: ['core','spectral','stereo','quality'] });
  const metrics = v2res?.metrics || {};
    const loud = metrics.loudness || {};
    const tp = metrics.truePeak || {};
    const core = metrics.core || {};
    const stereo = metrics.stereo || {};
    const tonal = metrics.tonalBalance || {};

    // Adapter: mapear para o formato jÃ¡ consumido pelo front (technicalData)
    baseAnalysis.technicalData = baseAnalysis.technicalData || {};
    const td = baseAnalysis.technicalData;

    // NÃ£o remover chaves existentes; adicionar novas como opcionais
    td.lufsIntegrated = isFinite(loud.lufs_integrated) ? loud.lufs_integrated : null;
    td.lra = isFinite(loud.lra) ? loud.lra : (loud.lra === 0 ? 0 : null);
    td.truePeakDbtp = isFinite(tp.true_peak_dbtp) ? tp.true_peak_dbtp : null;
    td.spectralCentroid = isFinite(core.spectralCentroid) ? core.spectralCentroid : null;
    td.spectralRolloff85 = isFinite(core.spectralRolloff) ? core.spectralRolloff : null;
    td.spectralFlux = isFinite(core.spectralFlux) ? core.spectralFlux : null;
    td.stereoCorrelation = isFinite(stereo.correlation) ? stereo.correlation : null;
    td.balanceLR = isFinite(stereo.balance) ? stereo.balance : null;
    td.tonalBalance = tonal && typeof tonal === 'object' ? tonal : null;
  // Extras para visual completo
  td.crestFactor = isFinite(core.crestFactor) ? core.crestFactor : null;
  td.stereoWidth = isFinite(stereo.width) ? stereo.width : null;
  td.monoCompatibility = typeof stereo.monoCompatibility === 'string' ? stereo.monoCompatibility : null;
  td.spectralFlatness = isFinite(core.spectralFlatness) ? core.spectralFlatness : null;
  td.dcOffset = isFinite(core.dcOffset) ? core.dcOffset : null;
  td.clippingSamples = Number.isFinite(core.clippingEvents) ? core.clippingEvents : null;
  td.clippingPct = isFinite(core.clippingPercentage) ? core.clippingPercentage : null;

  // Scores de qualidade e tempo total de processamento
  baseAnalysis.qualityOverall = isFinite(metrics?.quality?.overall) ? metrics.quality.overall : null;
  baseAnalysis.qualityBreakdown = metrics?.quality?.breakdown || null;
  baseAnalysis.processingMs = Number.isFinite(v2res?.processingTime) ? v2res.processingTime : null;

    // FrequÃªncias dominantes: manter existentes; se vazio, usar do V2
    if ((!Array.isArray(td.dominantFrequencies) || td.dominantFrequencies.length === 0) && metrics?.spectral?.dominantFrequencies) {
      td.dominantFrequencies = metrics.spectral.dominantFrequencies;
    }

    // Telemetria: chaves novas adicionadas
  const added = ['lufsIntegrated','lra','truePeakDbtp','spectralCentroid','spectralRolloff85','spectralFlux','stereoCorrelation','balanceLR','tonalBalance','crestFactor','stereoWidth','monoCompatibility','spectralFlatness','dcOffset','clippingSamples','clippingPct','qualityOverall','processingMs'];
    console.log('ğŸ›°ï¸ [Telemetry] Adapter Fase2 aplicado (novas chaves):', added.filter(k => k in td));
    console.log('ğŸ›°ï¸ [Telemetry] Valores mapeados:', {
      lufsIntegrated: td.lufsIntegrated,
      lra: td.lra,
      truePeakDbtp: td.truePeakDbtp,
      spectralCentroid: td.spectralCentroid,
      spectralRolloff85: td.spectralRolloff85,
      spectralFlux: td.spectralFlux,
      stereoCorrelation: td.stereoCorrelation,
      balanceLR: td.balanceLR,
      tonalBalance: td.tonalBalance ? {
        sub: td.tonalBalance.sub?.rms_db,
        low: td.tonalBalance.low?.rms_db,
        mid: td.tonalBalance.mid?.rms_db,
        high: td.tonalBalance.high?.rms_db,
      } : null
    });

    return baseAnalysis;
  }

  // (remoÃ§Ã£o do conversor WAV â€” nÃ£o Ã© mais necessÃ¡rio)

  // ğŸ”¬ Realizar anÃ¡lise completa
  performFullAnalysis(audioBuffer) {
    const analysis = {
      duration: audioBuffer.duration,
      sampleRate: audioBuffer.sampleRate,
      channels: audioBuffer.numberOfChannels,
      problems: [],
      suggestions: [],
      technicalData: {}
    };

    // Obter dados dos canais
    const leftChannel = audioBuffer.getChannelData(0);
    const rightChannel = audioBuffer.numberOfChannels > 1 ? audioBuffer.getChannelData(1) : leftChannel;

    // ğŸ“Š AnÃ¡lise de Volume e DinÃ¢mica
    analysis.technicalData.peak = this.findPeakLevel(leftChannel);
    analysis.technicalData.rms = this.calculateRMS(leftChannel);
    analysis.technicalData.dynamicRange = this.calculateDynamicRange(leftChannel);

    // ğŸ¯ AnÃ¡lise de FrequÃªncias Dominantes
    analysis.technicalData.dominantFrequencies = this.findDominantFrequencies(leftChannel, audioBuffer.sampleRate);

    // ğŸ” Detectar Problemas Comuns
    this.detectCommonProblems(analysis);

    // ğŸ’¡ Gerar SugestÃµes TÃ©cnicas
    this.generateTechnicalSuggestions(analysis);

    return analysis;
  }

  // ğŸ“ˆ Encontrar nÃ­vel de pico
  findPeakLevel(channelData) {
    let peak = 0;
    for (let i = 0; i < channelData.length; i++) {
      const sample = Math.abs(channelData[i]);
      if (sample > peak) {
        peak = sample;
      }
    }
    // Evitar log de zero
    if (peak === 0) peak = 0.000001;
    return 20 * Math.log10(peak); // Converter para dB
  }

  // ğŸ“Š Calcular RMS (Volume mÃ©dio)
  calculateRMS(channelData) {
    let sum = 0;
    for (let i = 0; i < channelData.length; i++) {
      sum += channelData[i] * channelData[i];
    }
    const rms = Math.sqrt(sum / channelData.length);
    // Evitar log de zero
    if (rms === 0) return -Infinity;
    return 20 * Math.log10(rms); // Converter para dB
  }

  // ğŸšï¸ Calcular range dinÃ¢mico
  calculateDynamicRange(channelData) {
    const peak = this.findPeakLevel(channelData);
    const rms = this.calculateRMS(channelData);
    
    // Verificar valores vÃ¡lidos
    if (rms === -Infinity || isNaN(peak) || isNaN(rms)) {
      return 0;
    }
    
    return Math.abs(peak - rms);
  }

  // ğŸµ Encontrar frequÃªncias dominantes
  findDominantFrequencies(channelData, sampleRate) {
    console.log('ğŸ¯ Iniciando anÃ¡lise de frequÃªncias...');
    
    // ImplementaÃ§Ã£o simplificada e mais rÃ¡pida
    const fftSize = 256; // Reduzido para melhor performance
    const frequencies = [];
    const maxSections = 20; // Limitar nÃºmero de seÃ§Ãµes
    
    const stepSize = Math.max(fftSize * 4, Math.floor(channelData.length / maxSections));
    
    // Analisar diferentes seÃ§Ãµes do Ã¡udio
    for (let i = 0; i < channelData.length - fftSize && frequencies.length < maxSections; i += stepSize) {
      try {
        const section = channelData.slice(i, i + fftSize);
        const spectrum = this.simpleFFT(section);
        
        // Encontrar frequÃªncia dominante nesta seÃ§Ã£o
        let maxMagnitude = 0;
        let dominantBin = 0;
        
        for (let j = 1; j < spectrum.length / 2; j++) { // ComeÃ§ar do bin 1
          const magnitude = spectrum[j];
          if (magnitude > maxMagnitude) {
            maxMagnitude = magnitude;
            dominantBin = j;
          }
        }
        
        const dominantFreq = (dominantBin * sampleRate) / fftSize;
        if (dominantFreq > 20 && dominantFreq < 20000) { // Faixa audÃ­vel
          frequencies.push(dominantFreq);
        }
      } catch (error) {
        console.warn('Erro na anÃ¡lise de seÃ§Ã£o:', error);
        continue;
      }
    }

    console.log(`ğŸ¯ FrequÃªncias encontradas: ${frequencies.length}`);

    // Encontrar as frequÃªncias mais comuns
    const freqGroups = this.groupFrequencies(frequencies);
    return freqGroups.slice(0, 5); // Top 5 frequÃªncias
  }

  // ğŸ” FFT Simples (para anÃ¡lise bÃ¡sica de frequÃªncias)
  simpleFFT(samples) {
    // ImplementaÃ§Ã£o bÃ¡sica para detectar frequÃªncias dominantes
    const N = samples.length;
    const spectrum = new Array(N);
    
    // Limitar N para evitar travamento
    const maxN = Math.min(N, 512);
    
    for (let k = 0; k < maxN; k++) {
      let real = 0;
      let imag = 0;
      
      for (let n = 0; n < maxN; n++) {
        const angle = -2 * Math.PI * k * n / maxN;
        real += samples[n] * Math.cos(angle);
        imag += samples[n] * Math.sin(angle);
      }
      
      spectrum[k] = Math.sqrt(real * real + imag * imag);
    }
    
    // Preencher o resto com zeros
    for (let k = maxN; k < N; k++) {
      spectrum[k] = 0;
    }
    
    return spectrum;
  }

  // ğŸ“Š Agrupar frequÃªncias similares
  groupFrequencies(frequencies) {
    const groups = {};
    const tolerance = 50; // Hz
    
    frequencies.forEach(freq => {
      const rounded = Math.round(freq / tolerance) * tolerance;
      groups[rounded] = (groups[rounded] || 0) + 1;
    });
    
    return Object.entries(groups)
      .sort(([,a], [,b]) => b - a)
      .map(([freq, count]) => ({ frequency: parseFloat(freq), occurrences: count }));
  }

  // ğŸš¨ Detectar problemas comuns
  detectCommonProblems(analysis) {
    const { peak, rms, dynamicRange } = analysis.technicalData;

    // Problema: Clipping
    if (peak > -0.5) {
      analysis.problems.push({
        type: 'clipping',
        severity: 'high',
        message: 'Ãudio com clipping detectado',
        solution: 'Reduza o volume geral ou use limitador'
      });
    }

    // Problema: Volume muito baixo
    if (rms < -30) {
      analysis.problems.push({
        type: 'low_volume',
        severity: 'medium',
        message: 'Volume RMS muito baixo',
        solution: 'Aumente o volume ou use compressÃ£o'
      });
    }

    // Problema: Falta de dinÃ¢mica
    if (dynamicRange < 6) {
      analysis.problems.push({
        type: 'over_compressed',
        severity: 'medium',
        message: 'Ãudio muito comprimido',
        solution: 'Reduza compressÃ£o ou use compressÃ£o multibanda'
      });
    }

    // Problema: FrequÃªncias dominantes problemÃ¡ticas
    analysis.technicalData.dominantFrequencies.forEach(freq => {
      if (freq.frequency > 300 && freq.frequency < 600 && freq.occurrences > 10) {
        analysis.problems.push({
          type: 'muddy_mids',
          severity: 'medium',
          message: `FrequÃªncia problemÃ¡tica em ${Math.round(freq.frequency)}Hz`,
          solution: `Corte em ${Math.round(freq.frequency)}Hz com Q de 2-4`
        });
      }
    });
  }

  // ğŸ’¡ Gerar sugestÃµes tÃ©cnicas
  generateTechnicalSuggestions(analysis) {
    const { peak, rms, dominantFrequencies } = analysis.technicalData;

    // SugestÃµes baseadas no RMS
    if (rms > -14 && rms < -8) {
      analysis.suggestions.push({
        type: 'mastering',
        message: 'NÃ­vel ideal para streaming (-14 LUFS)',
        action: 'Seu Ã¡udio estÃ¡ no volume ideal para plataformas digitais'
      });
    }

    // SugestÃµes baseadas nas frequÃªncias
    const bassFreqs = dominantFrequencies.filter(f => f.frequency < 250);
    if (bassFreqs.length < 2) {
      analysis.suggestions.push({
        type: 'bass_enhancement',
        message: 'Pouca presenÃ§a de graves',
        action: 'Considere boost em 60-80Hz ou adicione sub-bass'
      });
    }

    const highFreqs = dominantFrequencies.filter(f => f.frequency > 8000);
    if (highFreqs.length < 1) {
      analysis.suggestions.push({
        type: 'brightness',
        message: 'Falta de brilho nos agudos',
        action: 'Adicione shelf em 10kHz ou excitador de harmÃ´nicos'
      });
    }

    // SugestÃ£o especÃ­fica para funk
    const funkKickRange = dominantFrequencies.filter(f => f.frequency >= 50 && f.frequency <= 100);
    if (funkKickRange.length > 0) {
      analysis.suggestions.push({
        type: 'funk_specific',
        message: 'FrequÃªncia de kick detectada - tÃ­pica do funk',
        action: `Optimize a faixa ${Math.round(funkKickRange[0].frequency)}Hz para mais punch`
      });
    }
  }

  // ğŸ¯ Gerar prompt personalizado para IA
  generateAIPrompt(analysis) {
    let prompt = `ğŸµ ANÃLISE TÃ‰CNICA DE ÃUDIO DETECTADA:\n\n`;
    
    prompt += `ğŸ“Š DADOS TÃ‰CNICOS:\n`;
    prompt += `â€¢ Peak: ${analysis.technicalData.peak.toFixed(1)}dB\n`;
    prompt += `â€¢ RMS: ${analysis.technicalData.rms.toFixed(1)}dB\n`;
    prompt += `â€¢ DinÃ¢mica: ${analysis.technicalData.dynamicRange.toFixed(1)}dB\n`;
    prompt += `â€¢ DuraÃ§Ã£o: ${analysis.duration.toFixed(1)}s\n`;
    prompt += `â€¢ Sample Rate: ${analysis.sampleRate}Hz\n`;
    prompt += `â€¢ Canais: ${analysis.channels}\n\n`;

    if (analysis.technicalData.dominantFrequencies.length > 0) {
      prompt += `ğŸ¯ FREQUÃŠNCIAS DOMINANTES:\n`;
      analysis.technicalData.dominantFrequencies.slice(0, 5).forEach(freq => {
        prompt += `â€¢ ${Math.round(freq.frequency)}Hz (${freq.occurrences}x detectada)\n`;
      });
      prompt += `\n`;
    }

    if (analysis.problems.length > 0) {
      prompt += `ğŸš¨ PROBLEMAS DETECTADOS:\n`;
      analysis.problems.forEach(problem => {
        prompt += `â€¢ ${problem.message}\n`;
        prompt += `  SoluÃ§Ã£o: ${problem.solution}\n`;
      });
      prompt += `\n`;
    }

    if (analysis.suggestions.length > 0) {
      prompt += `ğŸ’¡ SUGESTÃ•ES AUTOMÃTICAS:\n`;
      analysis.suggestions.forEach(suggestion => {
        prompt += `â€¢ ${suggestion.message}\n`;
        prompt += `  AÃ§Ã£o: ${suggestion.action}\n`;
      });
      prompt += `\n`;
    }

    prompt += `ğŸ¯ CONTEXTO: Sou um produtor musical que precisa de ajuda especÃ­fica para melhorar meu Ã¡udio. `;
    prompt += `Com base nesta anÃ¡lise tÃ©cnica REAL do meu arquivo, me forneÃ§a conselhos prÃ¡ticos e especÃ­ficos `;
    prompt += `incluindo valores exatos de EQ, compressÃ£o, limitaÃ§Ã£o e outros processamentos. `;
    prompt += `Se detectou frequÃªncias problemÃ¡ticas, me diga exatamente onde cortar/realÃ§ar e com qual Q. `;
    prompt += `Se o volume estÃ¡ inadequado, me diga os valores exatos de compressÃ£o e limitaÃ§Ã£o para corrigir.`;

  // âš ï¸ Regra obrigatÃ³ria para reforÃ§ar uso dos dados do JSON na resposta da IA
  prompt += `\n\nâš ï¸ REGRA OBRIGATÃ“RIA: Use obrigatoriamente todos os valores de Peak, RMS, DinÃ¢mica e FrequÃªncias Dominantes fornecidos no JSON para criar recomendaÃ§Ãµes tÃ©cnicas reais e especÃ­ficas de EQ, compressÃ£o, limitaÃ§Ã£o, saturaÃ§Ã£o e outros processamentos. Sempre inclua valores exatos nas recomendaÃ§Ãµes.`;

    return prompt;
  }
}

// ğŸŒŸ Interface simplificada para uso
window.audioAnalyzer = new AudioAnalyzer();

// ğŸ¤ FunÃ§Ã£o para analisar arquivo e enviar para chat
async function analyzeAndChat(file) {
  try {
    console.log('ğŸµ Iniciando anÃ¡lise de Ã¡udio...');
    
    const analysis = await window.audioAnalyzer.analyzeAudioFile(file);
    const aiPrompt = window.audioAnalyzer.generateAIPrompt(analysis);
    
    console.log('âœ… AnÃ¡lise concluÃ­da:', analysis);
    
    // Enviar prompt personalizado para o chat
    await sendAudioAnalysisToChat(aiPrompt, analysis);
    
  } catch (error) {
    console.error('âŒ Erro na anÃ¡lise:', error);
    alert('Erro ao analisar Ã¡udio. Verifique se Ã© um arquivo vÃ¡lido.');
  }
}

// ğŸ“¤ Enviar anÃ¡lise para chat
async function sendAudioAnalysisToChat(prompt, analysis) {
  // Simular envio de mensagem do usuÃ¡rio
  const message = `[ANÃLISE DE ÃUDIO] Analisei meu Ã¡udio e preciso de ajuda para melhorar. Aqui estÃ£o os dados tÃ©cnicos:\n\n${prompt}`;
  
  // Enviar para o sistema de chat existente
  if (window.sendMessage) {
    window.sendMessage(message);
  } else {
    console.log('Prompt gerado:', message);
  }
}

console.log('ğŸµ Audio Analyzer carregado com sucesso!');

// üéµ AUDIO ANALYZER API V2
// Endpoint para an√°lise avan√ßada de √°udio com m√©tricas profissionais

import { auth, db } from './firebaseAdmin.js';
import { AudioAnalysisResponseSchema, AudioAnalysisRequestSchema, validateAnalysisResponse, ANALYSIS_CONSTANTS } from '../schemas/audio-analysis.js';
import cors from 'cors';
import Meyda from 'meyda';

// Configura√ß√£o CORS
const corsMiddleware = cors({
  origin: process.env.NODE_ENV === 'development' ? '*' : [
    'https://prod-ai-teste.vercel.app',
    /^https:\/\/prod-ai-teste-[a-z0-9\-]+\.vercel\.app$/
  ],
  methods: ['POST', 'OPTIONS'],
  credentials: true,
  maxAge: 86400 // 24 horas
});

// Configura√ß√µes da an√°lise
const CONFIG = {
  MAX_FILE_SIZE: parseInt(process.env.AUDIO_MAX_FILE_SIZE) || ANALYSIS_CONSTANTS.MAX_FILE_SIZE,
  PROCESSING_TIMEOUT: parseInt(process.env.AUDIO_PROCESSING_TIMEOUT) || 45000,
  ENABLE_ADVANCED_METRICS: process.env.FEATURE_ADVANCED_METRICS === 'true',
  QUALITY_PRESET: process.env.ANALYSIS_QUALITY || 'balanced'
};

function runMiddleware(req, res, fn) {
  return new Promise((resolve, reject) => {
    fn(req, res, (result) => {
      if (result instanceof Error) return reject(result);
      return resolve(result);
    });
  });
}

// üéµ HANDLER PRINCIPAL
export default async function handler(req, res) {
  const startTime = Date.now();
  
  console.log('üéµ Audio Analyzer V2 API chamada:', {
    method: req.method,
    timestamp: new Date().toISOString(),
    userAgent: req.headers['user-agent']?.substring(0, 100)
  });

  try {
    await runMiddleware(req, res, corsMiddleware);
  } catch (err) {
    console.error('CORS error:', err);
    return res.status(403).json({ error: 'CORS error' });
  }

  if (req.method === 'OPTIONS') {
    return res.status(200).end();
  }

  if (req.method !== 'POST') {
    return res.status(405).json({ 
      error: 'M√©todo n√£o permitido',
      allowedMethods: ['POST']
    });
  }

  // Timeout de seguran√ßa
  const timeoutId = setTimeout(() => {
    if (!res.headersSent) {
      res.status(408).json({ 
        error: 'Timeout na an√°lise',
        processingTime: Date.now() - startTime
      });
    }
  }, CONFIG.PROCESSING_TIMEOUT);

  try {
    const { audioData, idToken, config: requestConfig } = req.body;

    // Valida√ß√£o da requisi√ß√£o
    const requestValidation = validateAnalysisRequest({ 
      config: requestConfig,
      userId: idToken ? 'authenticated' : undefined 
    });
    
    if (!requestValidation.success) {
      return res.status(400).json({ 
        error: 'Configura√ß√£o inv√°lida',
        details: requestValidation.error
      });
    }

    // Autentica√ß√£o (opcional mas recomendada)
    let uid = null;
    let email = null;
    
    if (idToken) {
      try {
        const decoded = await auth.verifyIdToken(idToken);
        uid = decoded.uid;
        email = decoded.email;
        console.log('üîê Usu√°rio autenticado:', email);
      } catch (err) {
        console.warn('‚ö†Ô∏è Token inv√°lido, continuando sem autentica√ß√£o:', err.message);
      }
    }

    // Valida√ß√£o do √°udio
    if (!audioData || typeof audioData !== 'string') {
      return res.status(400).json({ error: 'Dados de √°udio necess√°rios (base64)' });
    }

    // Decodificar e validar tamanho
    const audioBuffer = Buffer.from(audioData, 'base64');
    if (audioBuffer.length > CONFIG.MAX_FILE_SIZE) {
      return res.status(413).json({ 
        error: 'Arquivo muito grande',
        maxSize: `${Math.round(CONFIG.MAX_FILE_SIZE / 1024 / 1024)}MB`,
        receivedSize: `${Math.round(audioBuffer.length / 1024 / 1024)}MB`
      });
    }

    console.log('üéõÔ∏è Iniciando an√°lise:', {
      fileSize: `${Math.round(audioBuffer.length / 1024)}KB`,
      features: requestConfig?.features || ['core'],
      quality: requestConfig?.quality || CONFIG.QUALITY_PRESET
    });

    // An√°lise principal
    const analysisResult = await performAdvancedAnalysis(audioBuffer, {
      ...requestConfig,
      uid,
      quality: requestConfig?.quality || CONFIG.QUALITY_PRESET,
      enableAdvanced: CONFIG.ENABLE_ADVANCED_METRICS && (requestConfig?.advancedMetrics !== false)
    });

    const processingTime = Date.now() - startTime;
    
    // Construir resposta completa
    const response = {
      success: true,
      version: '2.0',
      timestamp: new Date().toISOString(),
      processingTime,
      ...analysisResult
    };

    // Validar resposta
    const validation = validateAnalysisResponse(response);
    if (!validation.success) {
      console.error('‚ùå Erro na valida√ß√£o da resposta:', validation.error);
      throw new Error('Erro na valida√ß√£o da resposta');
    }

    // Salvar analytics (async, n√£o bloqueia resposta)
    if (uid) {
      saveAnalysisMetrics(uid, {
        processingTime,
        fileSize: audioBuffer.length,
        features: requestConfig?.features || ['core'],
        quality: response.metrics.quality?.overall,
        timestamp: new Date()
      }).catch(err => console.warn('Analytics save failed:', err));
    }

    clearTimeout(timeoutId);
    
    console.log('‚úÖ An√°lise V2 conclu√≠da:', {
      processingTime: `${processingTime}ms`,
      metricsCount: Object.keys(response.metrics).length,
      problemsFound: response.diagnostics?.problems?.length || 0,
      overallScore: response.metrics.quality?.overall || 'N/A'
    });

    return res.status(200).json(validation.data);

  } catch (error) {
    clearTimeout(timeoutId);
    console.error('üí• Erro na an√°lise V2:', {
      error: error.message,
      stack: error.stack?.split('\n').slice(0, 3).join('\n'),
      processingTime: Date.now() - startTime
    });
    
    return res.status(500).json({ 
      error: 'Erro interno na an√°lise',
      details: process.env.NODE_ENV === 'development' ? error.message : 'Erro interno',
      processingTime: Date.now() - startTime
    });
  }
}

// üî¨ AN√ÅLISE PRINCIPAL
async function performAdvancedAnalysis(audioBuffer, config) {
  const analysisStart = Date.now();
  const steps = [];
  const warnings = [];
  const performance = {};

  try {
    // 1. DECODIFICA√á√ÉO E METADADOS
    steps.push('audio_decode');
    const decodeStart = Date.now();
    
    const audioContext = new (globalThis.AudioContext || globalThis.webkitAudioContext)({ sampleRate: 44100 });
    const decodedBuffer = await audioContext.decodeAudioData(audioBuffer.buffer.slice(audioBuffer.byteOffset, audioBuffer.byteOffset + audioBuffer.byteLength));
    
    performance.decode_time = Date.now() - decodeStart;
    steps.push('metadata_extract');

    const metadata = {
      duration: decodedBuffer.duration,
      sampleRate: decodedBuffer.sampleRate,
      channels: decodedBuffer.numberOfChannels,
      fileSize: audioBuffer.length,
      format: detectAudioFormat(audioBuffer),
      bitDepth: estimateBitDepth(decodedBuffer)
    };

    // Valida√ß√µes b√°sicas
    if (metadata.duration > ANALYSIS_CONSTANTS.MAX_DURATION) {
      warnings.push(`Dura√ß√£o muito longa: ${metadata.duration}s (max: ${ANALYSIS_CONSTANTS.MAX_DURATION}s)`);
    }

    // 2. AN√ÅLISE CORE (sempre executada)
    steps.push('core_analysis');
    const coreStart = Date.now();
    
    const leftChannel = decodedBuffer.getChannelData(0);
    const rightChannel = decodedBuffer.numberOfChannels > 1 ? decodedBuffer.getChannelData(1) : null;
    
    const coreMetrics = await analyzeCoreMetrics(leftChannel, rightChannel, decodedBuffer.sampleRate);
    performance.core_analysis = Date.now() - coreStart;

    // 3. AN√ÅLISE ESPECTRAL (se solicitada)
    let spectralData = null;
    if (config.features?.includes('spectral') || config.features?.includes('core')) {
      steps.push('spectral_analysis');
      const spectralStart = Date.now();
      spectralData = await analyzeSpectralFeatures(leftChannel, decodedBuffer.sampleRate, config.quality);
      performance.spectral_analysis = Date.now() - spectralStart;
    }

    // 4. AN√ÅLISE EST√âREO (se houver 2 canais)
    let stereoMetrics = null;
    if (rightChannel && (config.features?.includes('stereo') || config.features?.includes('core'))) {
      steps.push('stereo_analysis');
      const stereoStart = Date.now();
      stereoMetrics = analyzeStereoMetrics(leftChannel, rightChannel);
      performance.stereo_analysis = Date.now() - stereoStart;
    }

    // 5. AN√ÅLISE DE QUALIDADE E SCORES
    steps.push('quality_scoring');
    const qualityStart = Date.now();
    const qualityScores = calculateQualityScores(coreMetrics, spectralData, stereoMetrics, metadata);
    performance.quality_scoring = Date.now() - qualityStart;

    // 6. DIAGN√ìSTICO E SUGEST√ïES
    steps.push('diagnostics');
    const diagnosticsStart = Date.now();
    const diagnostics = generateDiagnosticsAndSuggestions(coreMetrics, spectralData, stereoMetrics, metadata);
    performance.diagnostics = Date.now() - diagnosticsStart;

    // 7. M√âTRICAS AVAN√áADAS (se habilitadas)
    let advancedMetrics = {};
    if (config.enableAdvanced) {
      steps.push('advanced_analysis');
      const advancedStart = Date.now();
      // TODO: Implementar m√©tricas avan√ßadas (LUFS, BPM, etc.) em fases futuras
      performance.advanced_analysis = Date.now() - advancedStart;
    }

    await audioContext.close();

    return {
      metadata,
      config: {
        features: config.features || ['core'],
        quality: config.quality || 'balanced',
        advancedMetrics: config.enableAdvanced || false
      },
      metrics: {
        core: {
          ...coreMetrics,
          ...spectralData // Merge spectral data com core
        },
        ...(stereoMetrics && { stereo: stereoMetrics }),
        quality: qualityScores,
        ...advancedMetrics
      },
      diagnostics,
      debug: {
        analysisSteps: steps,
        warnings,
        performance: {
          ...performance,
          total_time: Date.now() - analysisStart
        }
      }
    };

  } catch (error) {
    console.error('‚ùå Erro na an√°lise:', error);
    throw new Error(`Falha na an√°lise: ${error.message}`);
  }
}

// üéØ AN√ÅLISE CORE METRICS
async function analyzeCoreMetrics(leftChannel, rightChannel, sampleRate) {
  // Peak e RMS
  let peak = 0;
  let sumSquared = 0;
  let dcSum = 0;
  let clippedSamples = 0;
  
  for (let i = 0; i < leftChannel.length; i++) {
    const sample = leftChannel[i];
    const absSample = Math.abs(sample);
    
    // Peak
    if (absSample > peak) peak = absSample;
    
    // RMS
    sumSquared += sample * sample;
    
    // DC Offset
    dcSum += sample;
    
    // Clipping detection (threshold: 95% of full scale)
    if (absSample >= 0.95) clippedSamples++;
  }
  
  const rms = Math.sqrt(sumSquared / leftChannel.length);
  const peakDb = peak > 0 ? 20 * Math.log10(peak) : -Infinity;
  const rmsDb = rms > 0 ? 20 * Math.log10(rms) : -Infinity;
  const dynamicRange = peakDb - rmsDb;
  const crestFactor = peak / (rms + 1e-10);
  const dcOffset = dcSum / leftChannel.length;
  const clippingPercentage = (clippedSamples / leftChannel.length) * 100;

  return {
    peak: peakDb,
    rms: rmsDb,
    dynamicRange: Math.max(0, dynamicRange),
    crestFactor,
    dcOffset,
    clippingEvents: clippedSamples,
    clippingPercentage,
    dominantFrequencies: [] // Ser√° preenchido na an√°lise espectral
  };
}

// üåà AN√ÅLISE ESPECTRAL
async function analyzeSpectralFeatures(channelData, sampleRate, quality = 'balanced') {
  try {
    // Configurar Meyda
    const frameSize = quality === 'fast' ? 512 : quality === 'accurate' ? 2048 : 1024;
    const hopSize = Math.floor(frameSize / 4);
    
    // Analisar m√∫ltiplas janelas
    const features = [];
    const dominantFrequencies = [];
    
    for (let i = 0; i < channelData.length - frameSize; i += hopSize) {
      const frame = channelData.slice(i, i + frameSize);
      
      try {
        const frameFeatures = Meyda.extract([
          'spectralCentroid',
          'spectralRolloff',
          'spectralFlux',
          'spectralFlatness'
        ], frame);
        
        if (frameFeatures && !isNaN(frameFeatures.spectralCentroid)) {
          features.push(frameFeatures);
        }
        
        // Encontrar frequ√™ncias dominantes nesta janela
        const spectrum = computeSpectrum(frame);
        const dominantFreq = findDominantFrequency(spectrum, sampleRate);
        if (dominantFreq > 20 && dominantFreq < 20000) {
          dominantFrequencies.push({ frequency: dominantFreq, magnitude: 0.5 });
        }
        
      } catch (err) {
        // Ignora frames problem√°ticos
        continue;
      }
      
      // Limitar an√°lise para performance
      if (features.length >= 100) break;
    }
    
    if (features.length === 0) {
      return {
        spectralCentroid: null,
        spectralRolloff: null,
        spectralFlux: null,
        spectralFlatness: null,
        dominantFrequencies: []
      };
    }
    
    // Calcular m√©dias
    const avgCentroid = features.reduce((sum, f) => sum + (f.spectralCentroid || 0), 0) / features.length;
    const avgRolloff = features.reduce((sum, f) => sum + (f.spectralRolloff || 0), 0) / features.length;
    const avgFlux = features.reduce((sum, f) => sum + (f.spectralFlux || 0), 0) / features.length;
    const avgFlatness = features.reduce((sum, f) => sum + (f.spectralFlatness || 0), 0) / features.length;
    
    // Agrupar frequ√™ncias dominantes
    const groupedFreqs = groupDominantFrequencies(dominantFrequencies);
    
    return {
      spectralCentroid: isFinite(avgCentroid) ? avgCentroid : null,
      spectralRolloff: isFinite(avgRolloff) ? avgRolloff : null,
      spectralFlux: isFinite(avgFlux) ? avgFlux : null,
      spectralFlatness: isFinite(avgFlatness) ? avgFlatness : null,
      dominantFrequencies: groupedFreqs.slice(0, 10)
    };
    
  } catch (error) {
    console.warn('‚ö†Ô∏è Erro na an√°lise espectral:', error);
    return {
      spectralCentroid: null,
      spectralRolloff: null,
      spectralFlux: null,
      spectralFlatness: null,
      dominantFrequencies: []
    };
  }
}

// üéµ AN√ÅLISE EST√âREO
function analyzeStereoMetrics(leftChannel, rightChannel) {
  let correlation = 0;
  let leftPower = 0;
  let rightPower = 0;
  let midPower = 0;
  let sidePower = 0;
  
  const length = Math.min(leftChannel.length, rightChannel.length);
  
  for (let i = 0; i < length; i++) {
    const left = leftChannel[i];
    const right = rightChannel[i];
    
    // Correla√ß√£o
    correlation += left * right;
    
    // Pot√™ncia dos canais
    leftPower += left * left;
    rightPower += right * right;
    
    // Mid/Side
    const mid = (left + right) / 2;
    const side = (left - right) / 2;
    midPower += mid * mid;
    sidePower += side * side;
  }
  
  // Normalizar
  correlation /= length;
  leftPower /= length;
  rightPower /= length;
  midPower /= length;
  sidePower /= length;
  
  // Calcular m√©tricas
  const totalPower = leftPower + rightPower;
  const balance = totalPower > 0 ? (rightPower - leftPower) / totalPower : 0;
  const width = midPower > 0 ? Math.sqrt(sidePower / midPower) : 0;
  
  // Determinar compatibilidade mono
  let monoCompatibility = 'excellent';
  if (correlation < 0.7) monoCompatibility = 'poor';
  else if (correlation < 0.85) monoCompatibility = 'fair';
  else if (correlation < 0.95) monoCompatibility = 'good';
  
  return {
    correlation: Math.max(-1, Math.min(1, correlation)),
    width: Math.max(0, Math.min(2, width)),
    balance: Math.max(-1, Math.min(1, balance)),
    monoCompatibility,
    phaseIssues: correlation < 0.5
  };
}

// üìä C√ÅLCULO DE SCORES DE QUALIDADE
function calculateQualityScores(coreMetrics, spectralData, stereoMetrics, metadata) {
  const scores = {
    dynamics: 50,
    frequency: 50,
    stereo: 50,
    loudness: 50,
    technical: 50
  };
  
  // Score de din√¢mica (baseado no dynamic range)
  if (coreMetrics.dynamicRange >= 12) scores.dynamics = 100;
  else if (coreMetrics.dynamicRange >= 8) scores.dynamics = 80;
  else if (coreMetrics.dynamicRange >= 6) scores.dynamics = 60;
  else if (coreMetrics.dynamicRange >= 4) scores.dynamics = 40;
  else scores.dynamics = 20;
  
  // Score de loudness (baseado no RMS)
  if (coreMetrics.rms >= -16 && coreMetrics.rms <= -12) scores.loudness = 100;
  else if (coreMetrics.rms >= -20 && coreMetrics.rms <= -10) scores.loudness = 80;
  else if (coreMetrics.rms >= -25 && coreMetrics.rms <= -8) scores.loudness = 60;
  else scores.loudness = 40;
  
  // Score t√©cnico (baseado em clipping e DC offset)
  scores.technical = 100;
  if (coreMetrics.clippingPercentage > 0.1) scores.technical -= 30;
  if (Math.abs(coreMetrics.dcOffset) > 0.01) scores.technical -= 20;
  if (coreMetrics.peak > -1) scores.technical -= 25;
  
  // Score de frequ√™ncia
  if (spectralData?.spectralCentroid) {
    const centroid = spectralData.spectralCentroid;
    if (centroid >= 1000 && centroid <= 3000) scores.frequency = 90;
    else if (centroid >= 500 && centroid <= 5000) scores.frequency = 75;
    else scores.frequency = 60;
  }
  
  // Score est√©reo
  if (stereoMetrics) {
    if (stereoMetrics.monoCompatibility === 'excellent') scores.stereo = 95;
    else if (stereoMetrics.monoCompatibility === 'good') scores.stereo = 80;
    else if (stereoMetrics.monoCompatibility === 'fair') scores.stereo = 65;
    else scores.stereo = 40;
  }
  
  // Score geral (m√©dia ponderada)
  const overall = Math.round(
    scores.dynamics * 0.25 +
    scores.frequency * 0.20 +
    scores.stereo * 0.20 +
    scores.loudness * 0.20 +
    scores.technical * 0.15
  );
  
  return {
    overall: Math.max(0, Math.min(100, overall)),
    breakdown: scores
  };
}

// üè• DIAGN√ìSTICO E SUGEST√ïES
function generateDiagnosticsAndSuggestions(coreMetrics, spectralData, stereoMetrics, metadata) {
  const problems = [];
  const suggestions = [];
  const feedback = [];

  // Detec√ß√£o de problemas
  if (coreMetrics.clippingPercentage > 0.05) {
    problems.push({
      type: 'clipping',
      severity: coreMetrics.clippingPercentage > 0.5 ? 'high' : 'medium',
      message: `${coreMetrics.clippingPercentage.toFixed(2)}% do √°udio com clipping`,
      solution: 'Reduza o volume geral em 3-6dB ou use um limitador suave'
    });
  }

  if (coreMetrics.rms < -30) {
    problems.push({
      type: 'low_volume',
      severity: 'medium',
      message: 'N√≠vel RMS muito baixo para streaming',
      solution: 'Aumente o volume ou aplique compress√£o/normaliza√ß√£o'
    });
  }

  if (coreMetrics.dynamicRange < 6) {
    problems.push({
      type: 'over_compressed',
      severity: 'medium',
      message: '√Åudio muito comprimido, falta din√¢mica',
      solution: 'Reduza compress√£o ou use compress√£o multibanda mais suave'
    });
  }

  if (Math.abs(coreMetrics.dcOffset) > 0.01) {
    problems.push({
      type: 'dc_offset',
      severity: 'low',
      message: 'DC offset detectado',
      solution: 'Aplique filtro high-pass em 20Hz'
    });
  }

  // Gera√ß√£o de sugest√µes
  if (coreMetrics.rms >= -16 && coreMetrics.rms <= -12) {
    suggestions.push({
      type: 'mastering',
      priority: 'high',
      message: 'N√≠vel ideal para streaming (-14 LUFS)',
      action: 'Volume perfeito para plataformas digitais'
    });
    feedback.push('‚úÖ N√≠vel de volume ideal para streaming');
  }

  if (spectralData?.spectralCentroid && spectralData.spectralCentroid > 4000) {
    suggestions.push({
      type: 'brightness',
      priority: 'medium',
      message: '√Åudio muito brilhante',
      action: 'Considere leve corte em 6-8kHz para suavizar'
    });
  }

  if (stereoMetrics?.width > 1.5) {
    suggestions.push({
      type: 'stereo_enhancement',
      priority: 'low',
      message: 'Imagem est√©reo muito ampla',
      action: 'Pode causar problemas em sistemas mono - teste a compatibilidade'
    });
  }

  // Feedback geral
  if (problems.length === 0) {
    feedback.push('üéµ Qualidade t√©cnica excelente!');
  }
  
  if (coreMetrics.dynamicRange > 10) {
    feedback.push('üéöÔ∏è √ìtima din√¢mica preservada');
  }

  return {
    problems: problems.slice(0, 10), // Max 10 problemas
    suggestions: suggestions.slice(0, 10), // Max 10 sugest√µes  
    feedback: feedback.slice(0, 5) // Max 5 feedbacks
  };
}

// üõ†Ô∏è FUN√á√ïES UTILIT√ÅRIAS

function detectAudioFormat(buffer) {
  // Detectar formato baseado nos magic numbers
  const signature = Array.from(buffer.slice(0, 12))
    .map(byte => byte.toString(16).padStart(2, '0'))
    .join('');
    
  if (signature.startsWith('494433')) return 'mp3'; // ID3
  if (signature.startsWith('fff3') || signature.startsWith('fff2')) return 'mp3';
  if (signature.startsWith('52494646')) return 'wav'; // RIFF
  if (signature.startsWith('4f676753')) return 'ogg'; // OggS
  if (signature.startsWith('664c6143')) return 'flac'; // fLaC
  
  return 'unknown';
}

function estimateBitDepth(audioBuffer) {
  // Estimativa simples baseada na precis√£o dos samples
  const samples = audioBuffer.getChannelData(0);
  let uniqueValues = new Set();
  
  for (let i = 0; i < Math.min(samples.length, 44100); i++) {
    uniqueValues.add(Math.round(samples[i] * 32768));
    if (uniqueValues.size > 65536) break;
  }
  
  if (uniqueValues.size <= 256) return 8;
  if (uniqueValues.size <= 65536) return 16;
  return 24;
}

function computeSpectrum(samples) {
  // FFT simples para encontrar frequ√™ncias dominantes
  const N = samples.length;
  const spectrum = new Array(N);
  
  for (let k = 0; k < N / 2; k++) {
    let real = 0, imag = 0;
    for (let n = 0; n < N; n++) {
      const angle = -2 * Math.PI * k * n / N;
      real += samples[n] * Math.cos(angle);
      imag += samples[n] * Math.sin(angle);
    }
    spectrum[k] = Math.sqrt(real * real + imag * imag);
  }
  
  return spectrum.slice(0, N / 2);
}

function findDominantFrequency(spectrum, sampleRate) {
  let maxMagnitude = 0;
  let dominantBin = 0;
  
  for (let i = 1; i < spectrum.length; i++) {
    if (spectrum[i] > maxMagnitude) {
      maxMagnitude = spectrum[i];
      dominantBin = i;
    }
  }
  
  return (dominantBin * sampleRate) / (spectrum.length * 2);
}

function groupDominantFrequencies(frequencies) {
  const groups = new Map();
  const tolerance = 50; // Hz
  
  frequencies.forEach(({ frequency, magnitude }) => {
    const rounded = Math.round(frequency / tolerance) * tolerance;
    if (!groups.has(rounded)) {
      groups.set(rounded, { frequency: rounded, magnitude: 0, occurrences: 0 });
    }
    groups.get(rounded).magnitude += magnitude;
    groups.get(rounded).occurrences += 1;
  });
  
  return Array.from(groups.values())
    .sort((a, b) => b.occurrences - a.occurrences)
    .map(group => ({
      frequency: group.frequency,
      magnitude: group.magnitude / group.occurrences,
      occurrences: group.occurrences
    }));
}

// üìä ANALYTICS (n√£o bloqueia resposta)
async function saveAnalysisMetrics(uid, metrics) {
  try {
    await db.collection('audio_analysis_metrics').add({
      uid,
      ...metrics,
      version: '2.0',
      createdAt: new Date()
    });
  } catch (error) {
    console.warn('Failed to save analytics:', error);
  }
}

function validateAnalysisRequest(data) {
  // Valida√ß√£o b√°sica para compatibilidade
  return { success: true, data };
}

console.log('üéµ Audio Analyzer API V2 carregado');
